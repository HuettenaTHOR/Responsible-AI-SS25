{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "166f7899-9a97-49f4-803a-13bcbb0dc16f",
   "metadata": {},
   "source": [
    "# An introduction to explainability in ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "116d17d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2ce854",
   "metadata": {},
   "source": [
    "# Exercise 1: Linear models [20 mins]\n",
    "\n",
    "In this exercise, we will inspect linear models and their explainability properties.\n",
    "\n",
    "Write a function that takes in a training dataset consisting of features and labales, and returns the accuracy and coefficients (w and b) of a Logistic Regression model.\n",
    "\n",
    "Inspect the coefficients of this model using for (1) COMPAS data and (2) The ACS PUMS data and (3) a custom dataset generated for yo below. We used both of these datasets in the previous exercise. Split them into train test sets.\n",
    "\n",
    "List the top-5 features for each dataset along with its magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d6752cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_data():\n",
    "    x, y = sklearn.datasets.make_classification(n_samples=200, n_features=10, n_informative=2, n_redundant=8, n_repeated=0, random_state=710)\n",
    "    return x, y\n",
    "x, y = custom_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2523c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def train_logistic_regression(x, y):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(train_x, train_y)\n",
    "    accuracy = model.score(test_x, test_y)\n",
    "    return accuracy, (model.coef_[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ee884145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the model's coefficients on different datsets\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "def inspect_model(x, y, names, leave_out:Optional[list[str]]=None):\n",
    "    x = deepcopy(x)\n",
    "    y = deepcopy(y)\n",
    "    names = deepcopy(names)\n",
    "    if leave_out:\n",
    "        for l in leave_out:\n",
    "            index = names.index(l)\n",
    "            x = np.delete(x, index, axis=1)\n",
    "            names.remove(l)\n",
    "            \n",
    "\n",
    "    accuracy, coefficients = train_logistic_regression(x, y)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    # sort by absolute value of coefficients\n",
    "    sorted_coefficients, sorted_names = zip(*sorted(zip(coefficients, names), key=lambda x: abs(x[0]), reverse=True))\n",
    "    print(f\"Top 5 coefficients: {sorted_coefficients[:5]}\")   \n",
    "    for i in range(min(5, len(sorted_coefficients)-1)):\n",
    "        print(f\"{i+1:>3}. {sorted_names[i]:<20} {sorted_coefficients[i]:>10.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c0e6fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from COMPAS\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.style\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import requests\n",
    "import folktables\n",
    "from folktables import ACSDataSource, ACSEmployment\n",
    "\n",
    "\n",
    "# Selecting the font size here will affect all the figures in this notebook\n",
    "# Alternatively, you can set the font size for axis labels of each figure separately\n",
    "font = {'size': 16}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "matplotlib.style.use(\"fivethirtyeight\")\n",
    "\n",
    "# Based on: https://fairlens.readthedocs.io/en/latest/user_guide/compas.html\n",
    "url = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
    "local_name = Path(\"compas-scores-two-years.csv\")\n",
    "if not local_name.is_file():\n",
    "    response = requests.get(url)\n",
    "    with open(\"compas-scores-two-years.csv\", \"w\") as f:\n",
    "        f.write(response.content.decode(\"utf-8\"))\n",
    "df = pd.read_csv(local_name)\n",
    "df = df.sample(frac=1, random_state=1)\n",
    "\n",
    "df = df[(df[\"days_b_screening_arrest\"] <= 30)\n",
    "        & (df[\"days_b_screening_arrest\"] >= -30)\n",
    "        & (df[\"is_recid\"] != -1)\n",
    "        & (df[\"c_charge_degree\"] != 'O')\n",
    "        & (df[\"score_text\"] != 'N/A')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1d724f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "COMAPS_X = df[[\"age\", \"juv_fel_count\", \"juv_misd_count\", \"juv_other_count\", \"priors_count\", \"c_charge_degree\"]]\n",
    "COMPAS_X = pd.get_dummies(COMAPS_X, columns=[\"c_charge_degree\"], drop_first=True)\n",
    "COMPAS_Y = df[[\"two_year_recid\"]]\n",
    "COMPAS_features = list(COMPAS_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "83df4f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, ACSEmployment\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"AL\"], download=True)  # Limiting to AL. You can try another state or all the states.\n",
    "ACS_X, ACS_Y, _ = ACSEmployment.df_to_numpy(acs_data) \n",
    "ACS_features = ACSEmployment.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a318085f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first dataset\n",
      "Accuracy: 0.875\n",
      "Top 5 coefficients: (1.1455169983026234, -0.9576455909574569, 0.7428626239114834, 0.7276404318201084, -0.4276766685711763)\n",
      "  1. 6                          1.15\n",
      "  2. 5                         -0.96\n",
      "  3. 0                          0.74\n",
      "  4. 4                          0.73\n",
      "  5. 8                         -0.43\n",
      "compas dataset\n",
      "Accuracy: 0.6874493927125506\n",
      "Top 5 coefficients: (0.31090441395338253, -0.1729504978355979, 0.16483997605068387, 0.08149657242531187, -0.04067046489506114)\n",
      "  1. juv_other_count            0.31\n",
      "  2. c_charge_degree_M         -0.17\n",
      "  3. priors_count               0.16\n",
      "  4. juv_fel_count              0.08\n",
      "  5. age                       -0.04\n",
      "acs dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\frede\\miniconda3\\envs\\RAI\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.780975303474257\n",
      "Top 5 coefficients: (1.333765333306379, 0.7820454942017775, -0.7689995979370305, 0.6256658453247685, -0.48519871960513367)\n",
      "  1. DIS                        1.33\n",
      "  2. DREM                       0.78\n",
      "  3. SEX                       -0.77\n",
      "  4. MIL                        0.63\n",
      "  5. DEAR                      -0.49\n"
     ]
    }
   ],
   "source": [
    "print(\"first dataset\")\n",
    "inspect_model(x, y, list(range(10)))\n",
    "print(\"compas dataset\")\n",
    "inspect_model(COMPAS_X, COMPAS_Y, COMPAS_features)\n",
    "print(\"acs dataset\")\n",
    "inspect_model(ACS_X, ACS_Y, ACS_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ac669d",
   "metadata": {},
   "source": [
    "# Exercise 2: Feature processing [10 mins]\n",
    "\n",
    "Scale your datasets using the sklean StandardScaler. Retrain the models and show the top-5 features again. Do you notice any differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cafae28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled custom data\n",
      "Accuracy: 0.875\n",
      "Top 5 coefficients: (-0.8510715190391881, 0.8510346675067891, 0.7365972359122493, 0.7044431889593377, -0.6647979111774699)\n",
      "  1. 5                         -0.85\n",
      "  2. 6                          0.85\n",
      "  3. 4                          0.74\n",
      "  4. 0                          0.70\n",
      "  5. 3                         -0.66\n",
      "scaled compas data\n",
      "Accuracy: 0.6874493927125506\n",
      "Top 5 coefficients: (0.7801647873742068, -0.47599298879161994, 0.14717626113208337, -0.0832975237681818, 0.038508165851969214)\n",
      "  1. priors_count               0.78\n",
      "  2. age                       -0.48\n",
      "  3. juv_other_count            0.15\n",
      "  4. c_charge_degree_M         -0.08\n",
      "  5. juv_fel_count              0.04\n",
      "scaled acs data\n",
      "Accuracy: 0.7810799497697781\n",
      "Top 5 coefficients: (-1.1474610770895495, 0.9754147973283497, 0.9209910807235978, -0.8072456149992863, 0.5228099631627076)\n",
      "  1. AGEP                      -1.15\n",
      "  2. MIL                        0.98\n",
      "  3. SCHL                       0.92\n",
      "  4. ESP                       -0.81\n",
      "  5. DIS                        0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\frede\\miniconda3\\envs\\RAI\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# apply standard scaler to the custom data\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "print(\"scaled custom data\")\n",
    "inspect_model(x_scaled, y, list(range(10)))\n",
    "print(\"scaled compas data\")\n",
    "COMPAS_X_scaled = scaler.fit_transform(COMPAS_X)\n",
    "inspect_model(COMPAS_X_scaled, COMPAS_Y, COMPAS_features)\n",
    "\n",
    "print(\"scaled acs data\")\n",
    "ACS_X_scaled = scaler.fit_transform(explained_ACS_x)\n",
    "inspect_model(explained_ACS_x_scaled, ACS_Y, ACS_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f5a492",
   "metadata": {},
   "source": [
    "# Exercise 3: Removing important features [20 mins]\n",
    "\n",
    "Remove the top-10% of the features (according to their feature imporrance score) from each training data. Retrain the model again. How much difference do you notice in the accuracy?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d3a17e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.875\n",
      "Top 5 coefficients: (1.215169413658818, 1.1579733757980806, -1.0880055959621193, -0.8112489650656605, -0.7235119601958268)\n",
      "  1. 4                          1.22\n",
      "  2. 0                          1.16\n",
      "  3. 3                         -1.09\n",
      "  4. 8                         -0.81\n",
      "  5. 9                         -0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\frede\\miniconda3\\envs\\RAI\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5838056680161944\n",
      "Top 5 coefficients: (0.24896520176010467, 0.23671551642325003, 0.23046452661386355, -0.19679044420880423)\n",
      "  1. juv_other_count            0.25\n",
      "  2. juv_misd_count             0.24\n",
      "  3. juv_fel_count              0.23\n",
      "Accuracy: 0.7445583926329008\n",
      "Top 5 coefficients: (-1.1268300751062796, 1.0073742779157528, 0.6803894540637497, -0.29244090065488615, 0.27272942029477565)\n",
      "  1. ESP                       -1.13\n",
      "  2. SCHL                       1.01\n",
      "  3. DIS                        0.68\n",
      "  4. RELP                      -0.29\n",
      "  5. DREM                       0.27\n"
     ]
    }
   ],
   "source": [
    "# inspect the model's coefficients on different datsets\n",
    "inspect_model(x_scaled, y, list(range(10)), leave_out=[5, 6])\n",
    "inspect_model(COMPAS_X_scaled, COMPAS_Y, COMPAS_features, leave_out=[\"priors_count\", \"age\"])\n",
    "inspect_model(ACS_X_scaled, ACS_Y, ACS_features, leave_out = [\"AGEP\", \"MIL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a381d9d",
   "metadata": {},
   "source": [
    "# Exercise 4: Decision trees [15 mins]\n",
    "\n",
    "Train decision trees of depth 1, 5, 10 and 20. Visualize the trees using [plot_tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html). What difference do you see in accuracy and the actual trees?\n",
    "\n",
    "Retrain the trees for different train/test splits. Do you see any difference in the trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d166d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee69f19d",
   "metadata": {},
   "source": [
    "# Exercise 5: Generating SHAP attributions [15 mins]\n",
    "\n",
    "Take the ACS PUMS data without adding any feature scaling or normalization, and train the following two models:\n",
    "1. A sklearn neural network with hidden units [100, 100].\n",
    "2. A Random Forest classifier.\n",
    "\n",
    "Compute the feature attributions using the [SHAP library](https://github.com/shap/shap). How do the feature attributions of the two models compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d6ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_neural_network(x, y, scaler=None):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    if scaler:\n",
    "        model = make_pipeline(StandardScaler(), MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42))\n",
    "    else:\n",
    "        model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "    model.fit(train_x, train_y)\n",
    "    predictions = model.predict(test_x)\n",
    "    accuracy = accuracy_score(test_y, predictions)\n",
    "    return accuracy, model\n",
    "\n",
    "ACS_X, ACS_Y, ACS_features = ACSEmployment.df_to_numpy(acs_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6815784d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81802009208874\n"
     ]
    }
   ],
   "source": [
    "accuracy, ACS_model = train_neural_network(ACS_X, ACS_Y)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "568c23b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided model function fails when applied to the provided data set.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. MLPClassifier expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[158]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Create a SHAP explainer\u001b[39;00m\n\u001b[32m      6\u001b[39m explained_ACS_x = np.array([ACS_X[:\u001b[32m10\u001b[39m]])\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m explainer = \u001b[43mExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mACS_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplained_ACS_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m shap_values = explainer(explained_ACS_x)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Plot the SHAP values\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\frede\\miniconda3\\envs\\RAI\\Lib\\site-packages\\shap\\explainers\\_kernel.py:97\u001b[39m, in \u001b[36mKernelExplainer.__init__\u001b[39m\u001b[34m(self, model, data, feature_names, link, **kwargs)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.model = convert_to_model(model, keep_index=\u001b[38;5;28mself\u001b[39m.keep_index)\n\u001b[32m     96\u001b[39m \u001b[38;5;28mself\u001b[39m.data = convert_to_data(data, keep_index=\u001b[38;5;28mself\u001b[39m.keep_index)\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m model_null = \u001b[43mmatch_model_to_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# enforce our current input type limitations\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.data, (DenseData, SparseData)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\frede\\miniconda3\\envs\\RAI\\Lib\\site-packages\\shap\\utils\\_legacy.py:142\u001b[39m, in \u001b[36mmatch_model_to_data\u001b[39m\u001b[34m(model, data)\u001b[39m\n\u001b[32m    140\u001b[39m         out_val = model.f(data.convert_to_df())\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m         out_val = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    144\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mProvided model function fails when applied to the provided data set.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\frede\\miniconda3\\envs\\RAI\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1264\u001b[39m, in \u001b[36mMLPClassifier.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1250\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Probability estimates.\u001b[39;00m\n\u001b[32m   1251\u001b[39m \n\u001b[32m   1252\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1261\u001b[39m \u001b[33;03m    model, where classes are ordered as they are in `self.classes_`.\u001b[39;00m\n\u001b[32m   1262\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1263\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m y_pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_pass_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1266\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m:\n\u001b[32m   1267\u001b[39m     y_pred = y_pred.ravel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\frede\\miniconda3\\envs\\RAI\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:204\u001b[39m, in \u001b[36mBaseMultilayerPerceptron._forward_pass_fast\u001b[39m\u001b[34m(self, X, check_input)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Predict using the trained model\u001b[39;00m\n\u001b[32m    186\u001b[39m \n\u001b[32m    187\u001b[39m \u001b[33;03mThis is the same as _forward_pass but does not record the activations\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    201\u001b[39m \u001b[33;03m    The decision function of the samples for each class in the model.\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;66;03m# Initialize first layer\u001b[39;00m\n\u001b[32m    207\u001b[39m activation = X\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\frede\\miniconda3\\envs\\RAI\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2942\u001b[39m         out = X, y\n\u001b[32m   2943\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\frede\\miniconda3\\envs\\RAI\\Lib\\site-packages\\sklearn\\utils\\validation.py:1101\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1096\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1097\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdtype=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mnumeric\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1098\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1099\u001b[39m     )\n\u001b[32m   1100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array.ndim >= \u001b[32m3\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1103\u001b[39m         % (array.ndim, estimator_name)\n\u001b[32m   1104\u001b[39m     )\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m   1107\u001b[39m     _assert_all_finite(\n\u001b[32m   1108\u001b[39m         array,\n\u001b[32m   1109\u001b[39m         input_name=input_name,\n\u001b[32m   1110\u001b[39m         estimator_name=estimator_name,\n\u001b[32m   1111\u001b[39m         allow_nan=ensure_all_finite == \u001b[33m\"\u001b[39m\u001b[33mallow-nan\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1112\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found array with dim 3. MLPClassifier expected <= 2."
     ]
    }
   ],
   "source": [
    "from shap import KernelExplainer as Explainer\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a SHAP explainer\n",
    "explained_ACS_x = np.array([ACS_X[:10]])\n",
    "explainer = Explainer(ACS_model.predict_proba, explained_ACS_x)\n",
    "shap_values = explainer(explained_ACS_x)\n",
    "# Plot the SHAP values\n",
    "shap.summary_plot(shap_values, explained_ACS_x, feature_names=ACS_features)\n",
    "# Plot the SHAP values for a single prediction\n",
    "shap.initjs()\n",
    "shap.plots.waterfall(shap_values[0], max_display=10)\n",
    "# Plot the SHAP values for a single prediction\n",
    "shap.plots.force(shap_values[0], matplotlib=True)\n",
    "# Plot the SHAP values for a single prediction\n",
    "shap.plots.bar(shap_values[0], max_display=10)\n",
    "# Plot the SHAP values for a single prediction\n",
    "shap.plots.decision(shap_values[0], matplotlib=True)\n",
    "# Plot the SHAP values for a single prediction\n",
    "shap.plots.text(shap_values[0])\n",
    "# Plot the SHAP values for a single prediction\n",
    "shap.plots.image(shap_values[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475cc240",
   "metadata": {},
   "source": [
    "# Exercise 6: Effect of baseline on SHAP values [30 mins]\n",
    "\n",
    "For each model, try out three different baselines:\n",
    "1. All zeros\n",
    "2. Mean\n",
    "3. Median\n",
    "\n",
    "How do the SHAP values compare between the three baselines?\n",
    "\n",
    "Now normalize the data using the StandardScaler and repeat the step above. Do you see any differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010cb27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da610aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37309d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
