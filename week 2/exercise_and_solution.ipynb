{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "166f7899-9a97-49f4-803a-13bcbb0dc16f",
   "metadata": {},
   "source": [
    "# An introduction to unfairness in ML\n",
    "\n",
    "In this exercise, you will learn about some basic machine learning tasks and the fairness issues that could arise there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0ae6f7-108d-42dd-9ecf-878c71bfde32",
   "metadata": {},
   "source": [
    "## Installing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1781683e-297f-488e-b065-057bc000f4b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install pandas folktables requests scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c177912-a4cf-4b0a-adc6-753ec525ab60",
   "metadata": {},
   "source": [
    "# Exercise 1: Training risk prediction models\n",
    "\n",
    "In this exercise, we will work with the ProPublic COMPAS dataset and train a risk prediction model.\n",
    "\n",
    "#### A quick intro to the dataset\n",
    "ProPublica, a news organization, compiled a list of all criminal oﬀenders screened through the COMPAS (Correctional Oﬀender Management Profiling for Alternative Sanctions) tool 5 in Broward County, Florida during 2013-2014. The data includes information on the defendents’ demographic features (gender, race, age), criminal history (charge for which the person was arrested, number of prior oﬀenses) and the risk score assigned to the oﬀender by COMPAS. ProPublica also collected the ground truth on whether or not these individuals actually recidivated within two years after the screening. To learn more about the dataset, see [this article](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm).\n",
    "\n",
    "#### Your task\n",
    "Your task will be to inspect this data and train a risk prediction model on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8ed35e-734a-4c42-9dbb-dd94f15ee6c7",
   "metadata": {},
   "source": [
    "## Exercise 1a: Download the data and select your features [20 mins]\n",
    "\n",
    "The code below downloads the COMPAS dataset for you. You will be predicting whether a defendent will recidivate (commit a crime within next two year). The corresponding label is `two_year_recid`.\n",
    "\n",
    "The COMPAS tool also trains a score ranging from 1 to 10 assigning the recidivism risk. We will train our own risk model and compare it against the COMPAS score.\n",
    "\n",
    "Inspect the data and identify the features that you would like to use for training your risk prediction model. Create a new pandas dataframe that only contains the features that you are interested in. This will be your feature vector $\\mathbf{x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb7d96b-dc99-458f-8946-4035be475cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folktables\n",
    "from folktables import ACSDataSource, ACSEmployment\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "\n",
    "# Based on: https://fairlens.readthedocs.io/en/latest/user_guide/compas.html\n",
    "url = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
    "local_name = Path(\"compas-scores-two-years.csv\")\n",
    "if not local_name.is_file():\n",
    "    response = requests.get(url)\n",
    "    with open(\"compas-scores-two-years.csv\", \"w\") as f:\n",
    "        f.write(response.content.decode(\"utf-8\"))\n",
    "df = pd.read_csv(local_name)\n",
    "df = df.sample(frac=1, random_state=1)\n",
    "\n",
    "df = df[(df[\"days_b_screening_arrest\"] <= 30)\n",
    "        & (df[\"days_b_screening_arrest\"] >= -30)\n",
    "        & (df[\"is_recid\"] != -1)\n",
    "        & (df[\"c_charge_degree\"] != 'O')\n",
    "        & (df[\"score_text\"] != 'N/A')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdda2b4-b1cb-475b-a6e3-96a028367cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the dataframe\n",
    "pd.set_option('display.max_columns', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949c8b60-9039-413b-a982-07cac5a86ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for separating out the features here\n",
    "df.columns # List all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87643f05-408d-403a-94db-08f17ea1f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "selected_cols = [  # The features that we will use for classification\n",
    "    \"age\",\n",
    "    \"juv_fel_count\",\n",
    "    \"juv_misd_count\",\n",
    "    \"juv_other_count\",\n",
    "    \"priors_count\",\n",
    "    \"c_charge_degree\",\n",
    "]\n",
    "sens = \"race\"  #  Will not use for classification but use it for fairness analysis\n",
    "label = \"two_year_recid\"  # The label we will try to predict\n",
    "\n",
    "df_selected = df[selected_cols + [sens] + [label]]\n",
    "df_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a482c95-03f6-432d-baf9-78f0eb26f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "for col in selected_cols:\n",
    "    plt.figure()\n",
    "    sns.histplot(df_selected, x=col, stat=\"probability\", hue=\"race\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39850aa5-7f7e-4e26-be86-72a924545a54",
   "metadata": {},
   "source": [
    "## Exercise 1b: Training and evaluating the risk predictors [25 mins]\n",
    "\n",
    "Train a scikit learn [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) model to predict the risk scores. Recall that the Logistic regression model assigns a probability of positive class as:\n",
    "$$\n",
    "p(y=1 | x) = 1 / [1 + \\exp(-d(\\mathbf{x}))]\n",
    "$$\n",
    "\n",
    "where $d(\\mathbf{x})$ is the distance from the decision boundary.\n",
    "\n",
    "You can access this probability using the [predict_proba](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba) method of the model.\n",
    "\n",
    "Your tasks are:\n",
    "1. Evaluate your risk prediction model based on accuracy, TPR, TNR, PPV, NPV and AUROC. Use a threshold of $0.5$ to binarize your decisions.\n",
    "2. Evaluate the COMPAS risk prediction model (in the column `v_decile_score`) with the same metrics. Use a threshold of $5$ to binarize the decisions. How do the two scores compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a70729-7648-405a-8ed8-28bf1773f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_selected[label].to_numpy()\n",
    "z = df_selected[sens].to_numpy()\n",
    "df_selected.drop(columns=[label, sens], inplace=True)\n",
    "df_one_hot = pd.get_dummies(df_selected)\n",
    "x = df_one_hot.to_numpy()\n",
    "x_train, x_test, y_train, y_test, z_train, z_test = train_test_split(x, y, z, random_state=1122)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "y_risk = model.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dbb76b-9216-4d32-8f8c-7def625e2542",
   "metadata": {},
   "source": [
    "# Exercise 2: Measuring unfairness (25 mins)\n",
    "Let us go back to the model we trained for the COMPAS data. Compute all the fairness metrics from the lecture slides. For computing fairness, consider the groups white and black. Can you think of ways to remove this unfairness?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc9e90-22a7-46ea-8fbf-56d94f277c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "def compute_model_stats(y, y_pred, y_risk):\n",
    "    tp = np.logical_and(y==1, y_pred==1).sum()\n",
    "    tn = np.logical_and(y==0, y_pred==0).sum()\n",
    "    fp = np.logical_and(y==0, y_pred==1).sum()\n",
    "    fn = np.logical_and(y==1, y_pred==0).sum()\n",
    "    return {\n",
    "        \"pos_frac\": (y_pred==1).mean(),\n",
    "        \"acc\": (y==y_pred).mean(),\n",
    "        \"tpr\": tp / (tp + fn),\n",
    "        \"tnr\": tn / (tn + fp),\n",
    "        \"ppv\": tp / (tp + fp),\n",
    "        \"npv\": tn / (tn + fn),\n",
    "        \"auc\": sklearn.metrics.roc_auc_score(y, y_risk),\n",
    "    }\n",
    "\n",
    "\n",
    "perf_overall = compute_model_stats(y_test, y_pred, y_risk)\n",
    "perf_white = compute_model_stats(y_test[z_test==\"Caucasian\"], y_pred[z_test==\"Caucasian\"], y_risk[z_test==\"Caucasian\"])\n",
    "perf_black = compute_model_stats(y_test[z_test==\"African-American\"], y_pred[z_test==\"African-American\"], y_risk[z_test==\"African-American\"])\n",
    "\n",
    "print(f\"| {'metric':<10} |  All |  B   |   W  |\")\n",
    "for k in perf_overall.keys():\n",
    "    print(f\"| {k:<10} | {perf_overall[k]:0.2f} | {perf_black[k]:0.2f} | {perf_white[k]:0.2f} |\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d44d4-f3ba-40d7-b46d-3cb2ac4a63dd",
   "metadata": {},
   "source": [
    "## Exercise 3: Transferability of risk scores (20 mins)\n",
    "\n",
    "You might recall the ACS employment data from the last lecture. We were trying to predict if someone is employed.\n",
    "\n",
    "In this exercise, we will measure how transferable the risk scores are over different states. Below is the code to train download the data for the state of Alabama (AL). Train a model and compute its accuracy (you did that in the last exercise too).\n",
    "\n",
    "How well does the model trained on AL generalize to different states like CA and TX?\n",
    "\n",
    "---\n",
    "Just to remind you, the features in the dataset are:\n",
    "\n",
    " * AGEP (Age)\n",
    " * SCHL (Educational attainment)\n",
    " * MAR (Marital status)\n",
    " * SEX (Sex): 1 denotes Male and 2 Female\n",
    " * DIS (Disability recode): 1 denotes a disability and 2 a disability\n",
    " * ESP (Employment status of parents)\n",
    " * MIG (Mobility status (lived here 1 year ago)\n",
    " * CIT (Citizenship status)\n",
    " * MIL (Military service)\n",
    " * ANC (Ancestry recode)\n",
    " * NATIVITY (Nativity)\n",
    " * RELP (Relationship)\n",
    " * DEAR (Hearing diﬃculty)\n",
    " * DEYE (Vision diﬃculty)\n",
    " * DREM (Cognitive diﬃculty)\n",
    " * RAC1P (Recoded detailed race code): (1 means white alone, 2 means Black or African American alone)\n",
    " * GCL (Grandparents living with grandchildren)\n",
    "\n",
    "\n",
    "For more details of the precise feature values, see Appendix B4 of the paper (https://arxiv.org/pdf/2108.04884)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8022a8d5-4c65-47eb-8e63-0fab151572d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"AL\"], download=True)  # Limiting to AL. You can try another state or all the states.\n",
    "x, y, group = ACSEmployment.df_to_numpy(acs_data)  # The group in this case is the race. It is also included in the features.\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print(f\"Test accuracy on AL: {(y_pred==y_test).mean(): 0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cab3d0-555d-4df7-981d-22b5b1d8267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "def print_performance(y_true, y_pred):\n",
    "    print(f\"Accuracy: {(y_true==y_pred).mean(): 0.2f}\")\n",
    "    print(\"Confusion matrix\")\n",
    "    with np.printoptions(precision=2):\n",
    "        print(sklearn.metrics.confusion_matrix(y_true, y_pred, normalize=\"true\"))\n",
    "\n",
    "def test_old_model(old_model, target_state):\n",
    "    x, y, group = ACSEmployment.df_to_numpy(data_source.get_data(states=[target_state], download=True))\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    own_model = LogisticRegression(max_iter=1000)\n",
    "    own_model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred_own = own_model.predict(x_test)\n",
    "    y_pred_old = old_model.predict(x_test)\n",
    "\n",
    "    print(f\"\\n== AL model performance on {target_state} data\")\n",
    "    print_performance(y_test, y_pred_old)\n",
    "    print(f\"\\n== {target_state} model performance on {target_state} data\")\n",
    "    print_performance(y_test, y_pred_own)\n",
    "\n",
    "test_old_model(model, \"CA\")\n",
    "print(\"---------\")\n",
    "test_old_model(model, \"TX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dbb3d5-8df8-4a7c-aecf-9e20116ba2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
