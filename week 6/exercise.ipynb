{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "166f7899-9a97-49f4-803a-13bcbb0dc16f",
   "metadata": {},
   "source": [
    "# Generating adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b2658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U torch torchvision --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116d17d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2ce854",
   "metadata": {},
   "source": [
    "# Exercise 1: Generating adversarial examples on MNIST data [45 mins]\n",
    "\n",
    "In this exercise, we will work with a computer vision model and generate adversarial examples. The generation procedure is very similar to the counterfactual generation code that developed last week.\n",
    "\n",
    "First, follow the process below to load the model and generate some predictions.\n",
    "\n",
    "(Adapted from [PyTorch](https://docs.pytorch.org/tutorials/beginner/fgsm_tutorial.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb1c046-bfa2-44c7-affa-09f075a3b6b3",
   "metadata": {},
   "source": [
    "First, download a pretrained neural network model from [here](https://drive.google.com/file/d/1HJV2nUHJqclXQ8flKvcWmjZ-OU5DGatl/view?usp=drive_link). Simply open the link and press `ctrl+S`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3f7491-1b88-4d5f-a32d-174ac7e625d8",
   "metadata": {},
   "source": [
    "Next, let us put together the structure of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8d4e3-ceea-4761-8fbe-61820861dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet Model definition\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a2b262-835e-4b53-b0a9-795ae07ef985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a cuda GPU, feel free to set the device to \"cuda\"\n",
    "device = \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Initialize the network\n",
    "model = Net().to(device)\n",
    "\n",
    "model_path = \"lenet_mnist_model.pth\"  # This is the file we downloaded\n",
    "# Load the pretrained model\n",
    "model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afba048a-4030-4bd1-b8bc-aeb878f2225f",
   "metadata": {},
   "source": [
    "Now let us download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4480fbc2-d857-4776-a36e-e7a4c62565ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Test dataset and dataloader declaration\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,)), # Normalize the images to 0 and 1\n",
    "            ])),\n",
    "        batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731917c0-f924-45b4-89da-6ca7a389a139",
   "metadata": {},
   "source": [
    "Some helper functions to convert the images back to the original scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3399e627-a2c3-4404-a052-9e62047dbac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restores the tensors to their original scale\n",
    "def denorm(batch, mean=[0.1307], std=[0.3081]):\n",
    "    \"\"\"\n",
    "    Convert a batch of tensors to their original scale.\n",
    "\n",
    "    Args:\n",
    "        batch (torch.Tensor): Batch of normalized tensors.\n",
    "        mean (torch.Tensor or list): Mean used for normalization.\n",
    "        std (torch.Tensor or list): Standard deviation used for normalization.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: batch of tensors without normalization applied to them.\n",
    "    \"\"\"\n",
    "    if isinstance(mean, list):\n",
    "        mean = torch.tensor(mean).to(device)\n",
    "    if isinstance(std, list):\n",
    "        std = torch.tensor(std).to(device)\n",
    "\n",
    "    return batch * std.view(1, -1, 1, 1) + mean.view(1, -1, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96855297-cb5d-447f-b0c1-e20492a2c63f",
   "metadata": {},
   "source": [
    "Let us compute the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578369cb-c6d1-48c6-a668-b930c4a2da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm \n",
    "labels = []\n",
    "preds = []\n",
    "for inp in tqdm.tqdm(test_loader):\n",
    "    x, y = inp\n",
    "    y_hat = model(x).argmax(-1).item()\n",
    "    labels.append(y.item())\n",
    "    preds.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b39891e-799e-4607-ba0a-2261c4dc4877",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "preds = np.array(preds)\n",
    "print(f\"Accuracy: {(labels==preds).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fa317b-d0f9-4241-8701-5439e4db7f7b",
   "metadata": {},
   "source": [
    "Now let us plot the last image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517389ec-8e11-4ec7-9c0e-f66e3fb175ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(denorm(x).squeeze(0,1), cmap=\"gray\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de68a4-eab8-42bb-beb0-7aab29400bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1556e1f0-1b50-4925-8692-5d736d2d7fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871dfcbc-63ce-462f-be0f-41c670d446c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2b69496-4d94-453b-b18b-a1b81a0abd56",
   "metadata": {},
   "source": [
    "## Your task\n",
    "\n",
    "Write a function that given an input example and a target label, generates an adversarial example using the FGSM method.\n",
    "\n",
    "Plot the original and the adversarial method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5bdbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3761f814",
   "metadata": {},
   "source": [
    "# Exercise 2: Counterfactual examples with sparsity [25 mins]\n",
    "\n",
    "Take the Census Income prediction task from last lecture. Generate counterfactuals with a L1 distance metric as a part of the objective function.\n",
    "\n",
    "Try different strenghts of the L1 norm. What differences do you observe w.r.t. the original counterfactual?\n",
    "\n",
    "You can use the solution from the last week. Its already uploaded on Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db7fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f7830e",
   "metadata": {},
   "source": [
    "# Exercise 3: Feature-aware distance function and post-processing counterfactuals [25 mins]\n",
    "\n",
    "Now change the distance function so that for categorical features, you do not use the L1 distance, but the $\\mathbb{I}[x \\neq x_c]$.\n",
    "\n",
    "Also, post process the counterfactuals. Change as many features as possible to original values while still preserving the counterfactual label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6d161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e10b32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
